{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from app.models import ONet\n",
    "from app.utils import seed_everything\n",
    "from app.utils_dataset import get_data, get_data_loaders\n",
    "from app.utils_model import train, model_inference, test_dlib\n",
    "from app.utils_plot import plot_ced_auc_test\n",
    "from app.settings import RANDOM_STATE, IMAGE_DIRS_300W_TRAIN, IMAGE_DIRS_300W_TEST, IMAGE_DIRS_MENPO_TRAIN, IMAGE_DIRS_MENPO_TEST, DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(RANDOM_STATE)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "train_df, val_df, test_df  = get_data(IMAGE_DIRS_MENPO_TRAIN, IMAGE_DIRS_MENPO_TEST, use_val_dataset=True)\n",
    "train_loader, val_loader, test_loader = get_data_loaders(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "# Получим 1 батч (картнки-метки) из обучающей выборки\n",
    "image, real_landmarks, resized_landmarks, rect = next(iter(train_loader))\n",
    "# cv2.rectangle(image, (rect[0],rect[1]), (rect[2],rect[3]), (255, 0, 0), 2)\n",
    "# for i in real_landmarks:\n",
    "#     image = cv2.circle(image, i, radius=0, color=(0, 0, 255), thickness=-1)\n",
    "# Расположим картинки рядом\n",
    "out = torchvision.utils.make_grid(image)\n",
    "\n",
    "imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели( Пока что возьмем O-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ONet()\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "# В качестве cost function используем кросс-энтропию\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    # weight_decay=2e-05\n",
    ")\n",
    "\n",
    "# scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "NAME = 'Menpo_dataset_model_O-Net'\n",
    "train_losses, val_losses, common_train_auc_0_08, common_val_auc_0_08, common_train_RMSE, common_val_RMSE = train(\n",
    "    model, optimizer, scheduler, criterion, train_loader, val_loader, num_epochs, NAME\n",
    ")\n",
    "\n",
    "#создаем словать из того что хотим сохранить\n",
    "# NAME = '300W_dataset_model_O-Net'\n",
    "state = {\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer' : optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'loss': train_losses[-1],\n",
    "    'common_train_auc_0_08': common_train_auc_0_08[-1],\n",
    "    'common_val_auc_0_08': common_val_auc_0_08[-1],\n",
    "    'common_train_RMSE': common_train_RMSE[-1],\n",
    "    'common_val_RMSE': common_val_RMSE[-1],\n",
    "}\n",
    "torch.save(state, f'/model_weights/checkpoints_{NAME}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим результаты для тестовой части"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "RMSE, test_auc_0_08, pred_landmarks_model = model_inference(model, test_loader, tqdm_desc='model_inference')\n",
    "\n",
    "# save result\n",
    "SAVE_PATH = '/results/predictions_300W_ONet.pkl'\n",
    "\n",
    "data_result= {'RMSE': RMSE, 'test_auc_0_08': test_auc_0_08, 'pred_landmarks_model': pred_landmarks_model}\n",
    "\n",
    "if os.path.exists(SAVE_PATH):\n",
    "      os.remove(SAVE_PATH)\n",
    "      \n",
    "with open(SAVE_PATH, 'wb') as fp:\n",
    "    pickle.dump(data_result, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим график CED для test_300W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(SAVE_PATH, 'rb') as fp:\n",
    "#      data_result = pickle.load(fp)\n",
    "RMSE_300W_test_ONet = data_result['RMSE']\n",
    "auc_0_08_300W_test_ONet = data_result['test_auc_0_08']\n",
    "plot_ced_auc_test(RMSE_300W_test_ONet, auc_0_08_300W_test_ONet, image_data = '300W')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты DLIB model На тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ced_auc_0_08_300W_dlib, RMSE_300W_test_dlib, pred_landmarks_300W_dlib  = test_dlib(datasets_path = '/home/ann/projects/vision_lab/df_300W_test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df  = get_data(IMAGE_DIRS_300W_TRAIN, IMAGE_DIRS_300W_TEST, use_val_dataset=True)\n",
    "train_loader, val_loader, test_loader = get_data_loaders(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
